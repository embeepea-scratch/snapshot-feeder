#! /usr/bin/python

# This script creates feed files for the images in the directory
# /var/www/Images.
# 
# Here's what it does, at the moment:
# 
# For each dataset_id in DATASET_IDS:
#     Make a list of all the image (png or zip) files in all the RESDIRS under /var/www/Images/dataset_id
#     Eliminate any images that do not have a version present in all RESDIRS for this dataset_id
#     Write all the remaining images to a file named /var/www/Images/dataset_id/dataset_id--YYYY-MM-DD.csv, formatted as URLs
#     Write the file /var/www/Images/dataset_id/feed.csv containing the URL of the file (/var/www/Images/dataset_id/dataset_id--YYYY-MM-DD.csv)
#       written in the previous step
# 
# Currently, this results in all images for each dataset_id being
# listed in a single csv file, and that single csv file being listed
# in the dataset_id's feed.csv file.
# 
# Ultimately, the intention is to modify this script so that it
# creates a new csv file for each dataset_id each time it is run,
# containing only the images from that dataset_id that were not
# present during the previous run; and it appends the name of the new
# csv file to the dataset_id's feed.csv file.  That hasn't been
# implemneted yet, though.


import os, re

date_generated = "2014-05-22"

URL_PREFIX = "http://54.235.203.129/Images/"

DIR = "/var/www/Images"

DATASET_IDS = [
    'averagetemp-monthly-cmb',
    'droughtoutlook-monthly-cpc',
    'oisst-daily-cdr',
    'precipoutlook-monthly-cpc',
    'probseverewx-dayofyear-spc',
    'tempanomaly-annual-nnvl',
    'tempanomaly-monthly-nnvl',
    'tempoutlook-monthly-cpc',
    'totalprecip-monthly-cmb',
    'usdroughtmonitor-weekly-ndmc'
    ]

RESDIRS = [
    '620',
    '1000',
    'hd',
    'hdsd',
    'diy'
]

#def subdirs(dir):
#    return [file for file in os.listdir(dir) if os.path.isdir(os.path.join(dir,file))]

#def imageDict(file):
#    m = re.search('(\d\d\d\d-\d\d-\d\d)\.((png)|(zip))$', file)
#    if m:
#        return { 'date' : m.group(1), 'file' : file }
#    else:
#        return None

def csvheader():
    """Return a string containing a comma-separated list of field names, which can be used as a header
    line in a CSV file; the string does NOT include a newline at the end."""
    return "guid,dsmn,ptk,stk,title,image_url,about,date_generated,download_title,download_url"

def csvline(dsmn, date, image_url, downloads):
    """Return a string containing a comma-separated list of field values for a single line in a CSV file,
    coresponding to a specific dsmn and date.  `dsmn` should be the id (machine name) of a dataset,
    `date` should be a date in YYYY-MM-DD format, and `downloads` should be an array of all the download images
    for the given data set and date."""
    guid = dsmn + "-" + date
    ptk  = re.sub('-\d\d-\d\d$', '', date)
    stk  = re.sub('^\d\d\d\d-', '', date)
    title = dsmn + " for " + date
    #image_url = URL_PREFIX + os.path.join(dsmn, '620', imgs['620'][date])
    #image_url = URL_PREFIX + os.path.join(dsmn, 'web', "%s--web--%s.png" % (dsmn, date))
    about = ""
    download_title = ", ".join(RESDIRS)
    download_url = ",".join([(URL_PREFIX + file) for file in downloads])
    return ",".join( ('"' + f + '"') for f in [guid,
                                               dsmn,
                                               ptk,
                                               stk,
                                               title,
                                               image_url,
                                               about,
                                               date_generated,
                                               download_title,
                                               download_url]
                     )

# return a dict of the images in subdir; keys are dates, values are filenames
def images(id,subdir):
    imageDict = {}
    for file in os.listdir(os.path.join(DIR,id,subdir)):
	m = re.search('(\d\d\d\d-\d\d-\d\d)\.((png)|(zip))$', file)
	if m:
            imageDict[m.group(1)] = file
    return imageDict

csvfiles = []

for dsmn in DATASET_IDS:
    imgs = {}
    datekeys = {}
    for subdir in RESDIRS:
        imgs[subdir] = images(dsmn,subdir)
        datekeys[subdir] = set( imgs[subdir].keys() )
    # set commonDates to the set of dates present in all img subdirs
    commonDates = datekeys[RESDIRS[0]].intersection( *[datekeys[subdir] for subdir in RESDIRS] )
    # check for images in each subdir whose dates are not in commonDates
    for subdir in RESDIRS:
        extraImgs = datekeys[subdir].difference(commonDates)
        if len(extraImgs) > 0:
            print "Warning: %1d images found in %s/%s/%s for dates not present in all %s/%s/* subdirs" % (
                len(extraImgs), DIR, dsmn, subdir, DIR, dsmn)
            for img in extraImgs:
                print "    %s" % img
    csvfile = os.path.join(dsmn, dsmn + "--" + date_generated + ".csv")
    nimages = 0
    web_image_dir = os.path.join(DIR, dsmn, "web")
    if not os.path.exists(web_image_dir):
        os.mkdir(web_image_dir)
    with open(os.path.join(DIR, csvfile), "w") as f:
        f.write(csvheader() + "\n")
        for date in sorted(commonDates):
            web_image = "%s--web--%s.png" % (dsmn, date)
            image_url = URL_PREFIX + os.path.join(dsmn, 'web', web_image)
            if os.path.exists(os.path.join(DIR, dsmn, "web", web_image)):
                os.remove(os.path.join(DIR, dsmn, "web", web_image))
            os.symlink(os.path.join("..", "620", imgs["620"][date]), os.path.join(DIR, dsmn, "web", web_image))
            f.write(csvline(dsmn, date, image_url,
                            [os.path.join(dsmn, res, imgs[res][date]) for res in RESDIRS]
                            ) + "\n")
            nimages += 1
    print "wrote %1d images to %s" % (nimages, os.path.join(DIR, csvfile))
    feedfile = os.path.join(DIR, dsmn, "feed.csv")
    with open(os.path.join(DIR, feedfile), "w") as f:
        f.write(URL_PREFIX + csvfile + "\n")
    print "wrote %s" % feedfile


#feedfile = os.path.join(DIR, "feed.csv")
#with open(feedfile, "w") as f:
#    for csvfile in csvfiles:
#        f.write(URL_PREFIX + csvfile + "\n")
#print "wrote %s" % feedfile

#guid:                 "usdm-2000-01-04"
#dsmn:                 "usdm"
#ptk:                  "2000"
#stk:                  "01-04"
#title:                "USDM for 2000-01-04",
#image_url:            "http://datasnapshots-images.nemac.com:8080/usdm/620/2000/usdm--620--2000-01-04.png",
#about:                "",
#date_generated:       "2000-01-04",
#download_title:       "620 PX, 940 PX, High res",
#download_url          "example.com,example.com,example.com"
#









